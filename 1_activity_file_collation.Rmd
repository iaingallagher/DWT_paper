---
title: "SA Activity Data Clustering"
author: "Iain J Gallagher - adapted by Paul McMenemy 18/10/2020"
date: "03/03/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---
```{r} 
if (!"tidyverse" %in% installed.packages()) ##
  install.packages("tidyverse") ##
library("tidyverse")##

if (!"lubridate" %in% installed.packages()) ##
  install.packages("lubridate") ##
library("lubridate") ##
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Intro
Activity data was recorded on elderly South Africans using the Actigraph instrument over 1 week.

## Load the data
There are 136 separate files in .csv format. Each of these has 10 leading rows that contain metadata and can be skipped. We will loop over these 136 files and:

* ignore the first 10 rows
* grab the uppercase letters and dates from the file names and concatenate these as ids
* collate the files into long format with an additional subject id column

The input filenames have the following format:

Firstname Lastname (yyyy-mm-dd)5sec60sec180secDataTable.csv

I will identify subjects in the data by initials and the date in parentheses in the filename; i.e. (X(X)X_yyy-mm-dd).

I tidied up a few typos/inconsistencies in the filenames (e.g., extra spaces etc.) and deleted a couple of .agd files that were included in the directory. The original files from Simone Tomaz are in the ```original_files``` directory.

#### Duplicated data
One subject has duplicated data (i.e., was assessed on separate occasions (MS (2018-10-04)5sec60sec180secDataTable.csv & MS (2018-11-07)5sec60sec180secDataTable.csv). The dataset marked 2018-11-07 looks complete (3700 measures) so I dropped the other dataset.

### Collate the files
The code below does the data collation & adds a subject id and weekday of measure to the raw data files. The final collated data is written out as ```collated_activity_data.csv'```.
```{r}
rm(list=ls())

folders <- "~/Dropbox (Personal)/Work/Results/SouthAfrica" # Iain's wd
# folders <- "M:/Sarcopenia Work/R Code" ## Paul's wd ##
setwd(folders) 

len_folders <- lengths(str_extract_all(folders, "[A-Z]")) ## used later to improve subj_id string

# function to generate an id string for file naming
id_string <- function(input_string){
  
  # create subject ID from file name
  input_string <- file_to_read
  id_vars <- str_replace(input_string, '5sec60sec180secDataTable.csv', '')
  subj_id <- str_extract(id_vars, "[:upper:]{1}" )[1:2]

  subj_id <- str_extract_all(id_vars, "[A-Z]")
  subj_id <- paste0(unlist(subj_id), collapse='')
  
  ## remove any characters that are part of the data folder address to tidy up subj_id
  subj_id <- substr(subj_id, len_folders+1, nchar(subj_id))

  date_id <- str_extract(id_vars, "[:digit:].*")
  date_id <- str_replace(date_id, '\\)', '')
  subj_id <- paste(subj_id, date_id, sep='_')
  
  return(subj_id)
}

# list of files to process
# we should sort out with some proper folder structure; issue added to repo 2 discuss with paul
# fls <- list.files(paste0(folders,'/actigraph_data/')) ##
fls <- list.files('actigraph_data/')

# all names, can delete later
# nms <-str_replace(fls, '5sec60sec180secDataTable.csv', '') %>% str_replace('\\(', '') %>% str_replace('\\)', '')
# nms <- as.data.frame(nms)
# write_csv(nms, 'DWT_paper/generated_data/all_names.csv')

# filter out any files which are not in .csv format (.agd files were throwing errors) ##
fls <- subset(fls, endsWith(fls, ".csv"))

# read first file
file_to_read <- paste(folders,'actigraph_data', fls[1], sep='/') ##

# create subject ID from file name
subj_id <- id_string(file_to_read)
```
### Suppress read_csv terminal outputs (PMCM 31/10/20)
Adding a break in the R Code here to allow terminal message output from 'read_csv' command to be suppressed

```{r message = FALSE}
# sex & ID info
# get data
all_data <- read_csv(file_to_read, skip=10)

# add subj_id & parse Date column to Date class
all_data <- all_data %>% mutate(subj = rep(subj_id, nrow(all_data))) %>% mutate(Date = as.Date(Date, format="%d/%m/%Y"))

# add day of week using wday function
all_data <- all_data %>% mutate(Weekday = wday(Date, label=TRUE, abbr=TRUE))

# read rest of files and append
for (f in fls[-1]){
  file_to_read <- paste(folders,'actigraph_data', f, sep='/')
  
  # apply id_string function
  subj_id <- id_string(file_to_read)
  # get data from .csv files - skip any that are not .csv file types
  
    fl <- read_csv(file_to_read, skip=10)

    fl <- fl %>% mutate(subj = rep(subj_id, nrow(fl))) %>% mutate(Date = as.POSIXct(Date, format="%d/%m/%Y"))
    fl <- fl %>% mutate(Weekday = wday(Date, label=TRUE, abbr=TRUE))
    all_data <- bind_rows(all_data, fl)
}

write_csv(all_data, 'collated_activity_data.csv')
```

### Drop some extra measurements
Some people have more than a weeks worth of data. We'll trim the data for each subject down to only a weeks worth of data.

```{r}
one_week_data <- all_data %>% mutate(Date = as_date(Date)) %>% group_by(subj) %>% 
  mutate(first_date = min(Date), last_date = first_date + days(6)) %>% filter(between(Date, unique(first_date), unique(last_date)))

# one_week_data %>% summarise(n = n_distinct(Date))
# everyone has 7 days
```

Somine Tomasz provided clinical data with details of sex and other clinical characteristics. We will filter the whole dataset down to separate male and female files.

```{r}
# male & female data
clin_data <- read_csv('clin_vars/Sarcopenia_study_FINAL_March_2021.csv')
clin_data <- clin_data %>% select(`ag ID`, gender0m1f) %>% rename(subj = `ag ID`) # colname in clin data same as colname in activity data; using `ag ID` because some weird bug won't reload the file!
# keep clinical data to just those in activity data, right join to include all rows in clin with match in activity
one_week_data <- right_join(clin_data, one_week_data, by = 'subj')
# filter datasets
male_data <- one_week_data_data %>% filter(gender0m1f == 0)
female_data <- one_week_data %>% filter(gender0m1f == 1)
# length(unique(female_data$subj)) # 109 females
# length(unique(male_data$subj)) # 23 males
```

We'll now write out the data.

```{r}
# write datasets
write_csv(male_data, 'DWT_paper/generated_data/male_activity_data.csv')
write_csv(female_data, 'DWT_paper/generated_data/female_activity_data.csv')
```

For each of the male and female datasets we will now split the data into files for separate week days. We will use these files later for weekday, weekend only etc analysis. 

```{r}
# takes dataset, parses out gender part for file name & splits into date specific files, naming file for weekday & date
get_days <- function(data_set){
  # for file name
  sex <- unique(ifelse(data_set$gender0m1f == 0, 'M', 'F'))
  
  # split all_data into separate days and output the separate date data as separate files
  days <- unique(as.character(data_set$Weekday))
  
  for (day in days){
    day_data <- data_set %>% filter(Weekday == day) %>% write_csv(paste(day, sex, 'data.csv', sep = '_'))
  }
}

get_days(male_data)
get_days(female_data)
```
